## AI ê¸°ë°˜ Proactive Deepfake Detection(ì„ ì œì  ë”¥í˜ì´í¬ íƒì§€)


<div align="center">

<img width="1280" height="720" alt="ì¸ë„¤ì¼ ì´ë¯¸ì§€" src="https://github.com/user-attachments/assets/598821b5-73a5-45fa-965e-958208b6d076" />

`#ë”¥í˜ì´í¬ íƒì§€` `#ì ëŒ€ì  ë…¸ì´ì¦ˆ ì‚½ì…` `#ì›Œí„°ë§ˆí¬ ì‚½ì…/íƒì§€` <br /> <br />
í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ì˜ìƒì˜ ì§„ì‹¤ì„ ì°¾ê³  ì½˜í…ì¸ ë¥¼ ì§€í‚¤ëŠ” **í†µí•© ë³´ì•ˆ ì†”ë£¨ì…˜** 'DeepTruth'ì…ë‹ˆë‹¤. 

</div>

---

### Repository
> Client: https://github.com/25-HF003/front-end <br />
> Spring Boot server: https://github.com/25-HF003/back-end <br/>
> Deepfake server: https://github.com/25-HF003/deepFake <br />
> Adversarial-Noise server: https://github.com/25-HF003/Adversarial-Noise <br />
> Watermark server: https://github.com/25-HF003/Watermark <br />

---

## **ğŸ’¡1. í”„ë¡œì íŠ¸ ê°œìš”**


**1-1. í”„ë¡œì íŠ¸ ì†Œê°œ**
- í”„ë¡œì íŠ¸ ëª… : DeepTruth
- í”„ë¡œì íŠ¸ ì •ì˜ : ë¶ˆë²•ì ì¸ ë”¥í˜ì´í¬ íƒì§€ ë° ìƒì„± ë°©ì§€ë¥¼ ìœ„í•œ AI ê¸°ë°˜ ì˜ìƒ ë¶„ì„ ì†”ë£¨ì…˜

**1-2. ê°œë°œ ë°°ê²½ ë° í•„ìš”ì„±**
- ìµœê·¼ ë”¥í˜ì´í¬ ê¸°ìˆ ì˜ ì•…ìš© ì‚¬ë¡€ê°€ ëŠ˜ì–´ ì‚¬íšŒì  ë¬¸ì œë¡œ ëŒ€ë‘ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì •ì¹˜ì¸ ê°€ì§œ ì—°ì„¤ ì˜ìƒê³¼ ìœ ëª…ì¸ í•©ì„± ìŒë€ë¬¼ ìœ í¬ëŠ” ë¬¼ë¡ , AIì˜ ë¬´ë‹¨ í•™ìŠµìœ¼ë¡œ ì›ì‘ìì˜ ì €ì‘ê¶Œ ì¹¨í•´ ë¬¸ì œê¹Œì§€ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ë³¸ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ë°˜ ë”¥í˜ì´í¬ íƒì§€ ì‹œìŠ¤í…œì„ ê°œë°œí•©ë‹ˆë‹¤. ë˜í•œ ì ëŒ€ì  ë…¸ì´ì¦ˆì™€ ë³´ì´ì§€ ì•ŠëŠ” ì›Œí„°ë§ˆí¬ ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ë”¥í˜ì´í¬ íƒì§€ ë° ì˜ˆë°© ê¸°ëŠ¥ì„ ê°•í™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

**1-3. í”„ë¡œì íŠ¸ íŠ¹ì¥ì **
* í†µí•©í˜• ë³´ì•ˆ ì‹œìŠ¤í…œ: ë”¥í˜ì´í¬ íƒì§€, ì ëŒ€ì  ë…¸ì´ì¦ˆ, ë¹„ê°€ì‹œì  ì›Œí„°ë§ˆí¬ ê¸°ìˆ ì„ ê²°í•©í•œ í†µí•©í˜• ë³´ì•ˆ ì†”ë£¨ì…˜
* ë¹„ê°€ì‹œì  ì›Œí„°ë§ˆí¬ ê¸°ìˆ : ìœ¡ì•ˆìœ¼ë¡œëŠ” ë³´ì´ì§€ ì•Šì§€ë§Œ AIê°€ ì¸ì‹ ê°€ëŠ¥í•œ ì›Œí„°ë§ˆí¬ë¡œ, ì½˜í…ì¸  ì†Œìœ ê¶Œ ë³´í˜¸ ë° ë³€ì¡° ì¶”ì ì— í™œìš©ë¨
* AI í•™ìŠµ ë°©í•´ ê¸°ìˆ : ì ëŒ€ì  ë…¸ì´ì¦ˆë¥¼ í™œìš©í•˜ì—¬ AIì˜ ë¬´ë‹¨ í•™ìŠµì„ ë°©í•´í•˜ê³  ì§€ì  ìì‚°ì„ ë³´í˜¸í•˜ëŠ” ê¸°ëŠ¥
* ì‚¬ìš©ì ë§ì¶¤í˜• ì´ì›í™” ê¸°ëŠ¥: ì¼ë°˜/ì •ë°€ ëª¨ë“œ ë° ìë™/ì •ë°€ ëª¨ë“œë¥¼ ì œê³µí•˜ì—¬ ì‚¬ìš©ìì˜ ëª©ì ê³¼ í•„ìš”ì— ë§ì¶° ìµœì í™”ëœ ê¸°ëŠ¥ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ì 
* í™•ì¥ì„± ë° ìœ ì—°ì„±: ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì •ì„ ì¡°ì •í•˜ì—¬ ë‹¤ì–‘í•œ í™˜ê²½ê³¼ ìš”êµ¬ ì‚¬í•­ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•˜ëŠ” ì‹¤ìš©ì  êµ¬ì¡°

**1-4. ì£¼ìš” ê¸°ëŠ¥**
- ë”¥í˜ì´í¬ íƒì§€ : ê¸°ë³¸ëª¨ë“œ/ì •ë°€ëª¨ë“œ ì„ íƒ ê°€ëŠ¥, ë”¥í˜ì´í¬ íƒì§€ ê²°ê³¼ëŠ” ìœ„í—˜í™•ë¥ (%)ê³¼ í•¨ê»˜ ì˜ì‹¬ì˜ì—­ì„ ë³´ì—¬ì£¼ê³  íƒì§€ëœ ì¥ë©´ì˜ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì œê³µ
- ì ëŒ€ì  ë…¸ì´ì¦ˆ ì‚½ì…: ìë™ëª¨ë“œ/ì •ë°€ëª¨ë“œ ì„ íƒ ê°€ëŠ¥, ì ëŒ€ì  ë…¸ì´ì¦ˆ ì‚½ì… ì´ë¯¸ì§€ì™€ í•¨ê»˜ ê³µê²© ì„±ê³µì—¬ë¶€, ë¶„ë¥˜ ë³€í™”, ì‹ ë¢°ë„ ë³€í™”, ì ëŒ€ì  ë…¸ì´ì¦ˆ ê°•ë„ ì •ë³´ ì œê³µ
- ì›Œí„°ë§ˆí¬ ì‚½ì…:  íŒŒì¼ì„ ë°›ì•„ ì›Œí„°ë§ˆí¬ë¥¼ ì‚½ì…/íƒì§€ ê°€ëŠ¥

**1-5. ê¸°ëŒ€ íš¨ê³¼ ë° í™œìš© ë¶„ì•¼**
- ê¸°ëŒ€íš¨ê³¼: ì‚¬íšŒÂ·ì •ì¹˜ì  ì•ˆì •ì„± í™•ë³´, ì°½ì‘ì ì§€ì  ì¬ì‚°ê¶Œ ë³´í˜¸, ì°¨ì„¸ëŒ€ AI ë³´ì•ˆ ê¸°ìˆ  í‘œì¤€ ì •ë¦½
- í™œìš©ë°©ì•ˆ: ì‚¬ë²• ì ˆì°¨ ë²•ì  ëŒ€ì‘ ì§€ì›, ì–¸ë¡ Â·ë¯¸ë””ì–´ì˜ ë³´ë„ ì˜ìƒ ë¬´ê²°ì„± ê²€ì¦, ë””ì§€í„¸ ì‘í’ˆ ì €ì‘ê¶Œ ë³´í˜¸

**1-6. ê¸°ìˆ  ìŠ¤íƒ**
- í”„ë¡ íŠ¸ì—”ë“œ : <img src="https://img.shields.io/badge/React-61DAFB?style=flat-square&logo=React&logoColor=white"> <img src="https://img.shields.io/badge/Next.js-000000?style=flat-square&logo=Next.js&logoColor=white"/> <img src="https://img.shields.io/badge/typescript-%23007ACC.svg?style=flat-square&logo=typescript&logoColor=white"> <img src="https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?style=flat-square&logo=tailwind-css&logoColor=white">
- ë°±ì—”ë“œ : <img src="https://img.shields.io/badge/java-007396?style=flat-square&logo=OpenJDK&logoColor=white"> <img src="https://img.shields.io/badge/Spring Boot-6DB33F?style=flat-square&logo=springboot&logoColor=black"/>
- AI/ML : <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=white"> <img src="https://img.shields.io/badge/Flask-000000?style=flat-square&logo=Flask&logoColor=white">
- ë°ì´í„°ë² ì´ìŠ¤ : <img src="https://img.shields.io/badge/MySQL-4479A1?style=flat-square&logo=MySQL&logoColor=white"> 
- í´ë¼ìš°ë“œ :  <img src="https://img.shields.io/badge/Amazon AWS-FF9900?style=flat-square&logo=amazonec2&logoColor=white"/>
- ë°°í¬ ë° ê´€ë¦¬ : <img src="https://img.shields.io/badge/docker-%230db7ed.svg?style=flat-square&logo=docker&logoColor=white"> 

---


## **ğŸ’¡2. íŒ€ì› ì†Œê°œ**
| <img width="80" height="100" src="https://avatars.githubusercontent.com/u/90364648?v=4" alt="ê°•ìˆ˜ì •"> | <img width="80" height="100" alt="ê¹€ë³´ë¯¼" src="https://avatars.githubusercontent.com/u/101878770?v=4" > | <img width="80" height="100" src="https://avatars.githubusercontent.com/u/123048615?v=4" width=90px alt="ì„œì§€í˜œ"/>| <img width="80" height="100" alt="ì—¬ê°•íœ˜" src="https://avatars.githubusercontent.com/u/101783655?v=4" > | 
|:---:|:---:|:---:|:---:|
| **ê°•ìˆ˜ì •** | **ê¹€ë³´ë¯¼** | **ì„œì§€í˜œ(íŒ€ì¥)** | **ì—¬ê°•íœ˜** | 
| [@kangsujung](https://github.com/kangsujung) | [@fsdffds](https://github.com/fsdffds)  | [@Jihye0623](https://github.com/jihye0623) | [@YO1231](https://github.com/YO1231) |
| â€¢ FrontEnd <br> â€¢ AI | â€¢ FrontEnd <br> â€¢ AI | â€¢ BackEnd <br> â€¢ AI |â€¢ BackEnd <br> â€¢ AI |

---
## **ğŸ’¡3. ì‹œìŠ¤í…œ êµ¬ì„±ë„**
- ì„œë¹„ìŠ¤ êµ¬ì„±ë„
<img width="500" height="500" alt="image" src="https://github.com/user-attachments/assets/78a8aae8-a3c3-418e-bd3e-0685a59d9413" />

- ì—”í‹°í‹° ê´€ê³„ë„
<img width="500" height="500" alt="ìŠ¤í¬ë¦°ìƒ·(8)" src="https://github.com/user-attachments/assets/779c8c02-8341-45d1-a807-16c7cc6812d2" />


---
## **ğŸ’¡4. ì‘í’ˆ ì†Œê°œì˜ìƒ**
[![Video Label](http://img.youtube.com/vi/6XYoLJTWHXI/0.jpg)](https://youtu.be/6XYoLJTWHXI?si=1JbJn2mcm2SDC6fU)

---
## **ğŸ’¡5. í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ**

### **:boom:ë”¥í˜ì´í¬ íƒì§€ ê¸°ëŠ¥**
#### 1) DNNìœ¼ë¡œ ì–¼êµ´ ê²€ì¶œì„ ì‹œë„í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì¬ì‹œë„í•˜ê±°ë‚˜ dlib íƒì§€ê¸°ë¡œ ì „í™˜í•˜ëŠ” ë“± ì—¬ëŸ¬ ë‹¨ê³„ì˜ í´ë°±(fallback)ì„ í†µí•´ ì•ˆì •ì ìœ¼ë¡œ ì–¼êµ´ì„ ì°¾ì•„ë‚´ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

```python
def robust_detect(frame, *, detector="dnn", dnn_conf=0.30, resize_long=720, max_boxes=5):
    H, W = frame.shape[:2]
    # 1ì°¨ DNN
    try:
        bboxes = detect_face_bboxes(frame, detector="dnn", dnn_conf=dnn_conf, max_boxes=max_boxes)
    except Exception as e:
        print("[ERR] dnn first pass:", repr(e), flush=True); 
        bboxes = []

    # ë¦¬ì‚¬ì´ì¦ˆ í›„ ì¬ì‹œë„
    if not bboxes:
        long_side = resize_long or 720
        scale = float(long_side) / float(max(H, W))
        fr = cv2.resize(frame, (int(W*scale), int(H*scale)), interpolation=cv2.INTER_AREA) if scale < 1.0 else frame
        try:
            b2 = detect_face_bboxes(fr, detector="dnn", dnn_conf=0.25, max_boxes=max_boxes)
        except Exception as e:
            print("[ERR] dnn resized pass:", repr(e), flush=True); 
            b2 = []
        if b2:
            inv = (1.0/scale) if scale>0 else 1.0
            bboxes = [(int(x1*inv), int(y1*inv), int(x2*inv), int(y2*inv), conf) for (x1,y1,x2,y2,conf) in b2]
    
    # í´ë°±
    if not bboxes and detector != "dlib":
        try:
            fb = detect_face_bboxes(frame, detector="dlib", max_boxes=max_boxes) or []
            if fb:
                print("[DBG] fallback dlib hit", flush=True)
            bboxes = fb
        except Exception as e:
            print("[ERR] dlib fallback:", repr(e), flush=True); 
    return bboxes
```

#### 2) ë™ì˜ìƒì—ì„œ í”„ë ˆì„ì„ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§í•˜ì—¬ ë”¥í˜ì´í¬ ì—¬ë¶€ë¥¼ ì¶”ë¡ í•˜ê³ , ì§€ìˆ˜ ì´ë™ í‰ê· (EMA)ìœ¼ë¡œ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ë³´ì •í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ê³„ì‚°í•˜ëŠ” ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

```python
# ê· ë“± ìƒ˜í”Œë§
step = max(1, num_frames // max(1, sample_count))
target_indices = set([min(i*step, num_frames-1) for i in range(max(1, sample_count))])

ema = None
per_frame_conf = []
raw_conf_for_vote = []
results = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None:
        break

    if frame_idx in target_indices:
        # (ì •ë°€/ê¸°ë³¸ ëª¨ë“œì— ë”°ë¼ ì–¼êµ´ ê²€ì¶œ/ì „ì²˜ë¦¬/ì¶”ë¡ )
        # ...
        # ì¶”ë¡  í›„ EMA ì ìš©
        if ema is None:
            ema = conf_i  # ë˜ëŠ” conf
        else:
            ema = 0.5*conf_i + 0.5*ema
        conf_s = float(ema)

        raw_conf_for_vote.append((conf_i, q, l))
        per_frame_conf.append(conf_s)
        results.append({'pred': 1 if conf_s>=0.5 else 0, 'confidence': conf_s})
        # ...
    frame_idx += 1

```
<br/>

### **:boom:ì ëŒ€ì  ë…¸ì´ì¦ˆ ì‚½ì… ê¸°ëŠ¥**
#### ìë™(ì‹ ë¢°ë„ ê¸°ë°˜) ë˜ëŠ” ì •ë°€(ì‚¬ìš©ì ë ˆë²¨ ì„ íƒ) ëª¨ë“œë¡œ FGSM ê³µê²© ë° Gaussian Blur í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

```python
def fgsm_attack_with_blur(image_tensor, base_epsilon=0.015, base_sigma=0.4, mode='auto', level=2):
    image_tensor = image_tensor.clone().unsqueeze(0).requires_grad_(True)
    
    result = classify_with_art_model(image_tensor)
    if result[0] is None:  # ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ
        raise ValueError("ì›ë³¸ ì´ë¯¸ì§€ ë¶„ë¥˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    original_class, conf, original_pred = result
    
    # ëª¨ë“œë³„ epsilon ê²°ì •
    if mode == 'precision':
        # ì •ë°€ ëª¨ë“œ: ìë™ ëª¨ë“œì˜ ê° ë‹¨ê³„ì™€ ë™ì¼í•œ epsilon ì‚¬ìš©
        epsilon_levels = {
            1: base_epsilon,        # ê¸°ë³¸ (1.0ë°°)
            2: base_epsilon * 1.5,  # ì¤‘ê°„ (1.5ë°°)
            3: base_epsilon * 2.5,  # ê°•í•¨ (2.5ë°°)
            4: base_epsilon * 4.0   # ë§¤ìš° ê°•í•¨ (4.0ë°°)
        }
        eps = epsilon_levels.get(level, base_epsilon)
        sigma = base_sigma  # ê³ ì •
        auto_reason = None
        
    else:  # mode == 'auto'
        # ìë™ ëª¨ë“œ: ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ì • (ê¸°ì¡´ ë¡œì§)
        if conf > 0.99:
            eps = base_epsilon * 4.0
            sigma = base_sigma * 0.3
            auto_reason = "very_high_confidence"
        elif conf > 0.95:
            eps = base_epsilon * 2.5
            sigma = base_sigma * 0.5
            auto_reason = "high_confidence"
        elif conf > 0.9:
            eps = base_epsilon * 1.5
            sigma = base_sigma
            auto_reason = "medium_confidence"
        else:
            eps = base_epsilon
            sigma = base_sigma
            auto_reason = "low_confidence"
    
    # FGSM ê³µê²©
    try:
        # gradient ê³„ì‚°
        image_pil = transforms.ToPILImage()(image_tensor.squeeze().clamp(0, 1))
        inputs = art_processor(images=image_pil, return_tensors="pt")
        inputs['pixel_values'].requires_grad_(True)
        
        outputs = art_model(**inputs)
        target = torch.tensor([original_pred])
        loss = F.cross_entropy(outputs.logits, target)
        
        # Gradient ê¸°ë°˜ perturbation
        loss.backward()
        
        if inputs['pixel_values'].grad is not None:
            perturbation = eps * inputs['pixel_values'].grad.sign()
            # í¬ê¸° ë§ì¶¤
            if perturbation.shape != image_tensor.shape:
                perturbation = F.interpolate(perturbation, size=image_tensor.shape[2:], mode='bilinear')
            adv_image = image_tensor + perturbation
            print("[DEBUG] Gradient ê¸°ë°˜ FGSM ì ìš©")
        else:
            raise Exception("Gradient ê³„ì‚° ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"[WARN] ì˜ˆìˆ  ëª¨ë¸ gradient ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        perturbation = eps * torch.randn_like(image_tensor)
        adv_image = image_tensor + perturbation
    
    adv_image = torch.clamp(adv_image, 0, 1)
    
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
    adv_np = adv_image.squeeze(0).detach().cpu().numpy()
    adv_blur_np = np.stack([gaussian_filter(c, sigma=sigma) for c in adv_np])
    adv_blur = torch.from_numpy(adv_blur_np).unsqueeze(0)
```
<br/>

### **:boom:ì›Œí„°ë§ˆí¬ ì‚½ì… ê¸°ëŠ¥**
```python
@app.route('/watermark-insert', methods=['POST'])
def watermarkInsert():
    # 1. ì´ë¯¸ì§€ì™€ ë©”ì‹œì§€ ë°›ê¸°
    image_file = request.files.get('image')
    message = request.form.get('message', 'ETNL')
    assert len(message) <= 4, "ë©”ì‹œì§€ëŠ” 4ì ì´í•˜ë§Œ ê°€ëŠ¥"
    if not image_file or not message:
        return jsonify({"error": "image, message ë‘˜ ë‹¤ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
    # 2. ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    image = Image.open(image_file.stream).convert("RGB")
    img_pt = default_transform(image).unsqueeze(0).to(device)
    
    # 3. ë©”ì‹œì§€ ì „ì²˜ë¦¬
    wm_bits = ''.join(f"{ord(c):08b}" for c in message)
    wm_bits = wm_bits.ljust(32, '0')[:32]
    wm_msg = torch.tensor([[int(bit) for bit in wm_bits]], dtype=torch.float32).to(device)
    
    # 3. ì›Œí„°ë§ˆí¬ ì‚½ì…
    outputs = wam.embed(img_pt, wm_msg)
    mask = create_random_mask(img_pt, num_masks=1, mask_percentage=0.5)
    img_w = outputs['imgs_w'] * mask + img_pt * (1 - mask)
    
    # 4. ì´ë¯¸ì§€ í›„ì²˜ë¦¬ 
    out_img = unnormalize_img(img_w).squeeze(0).detach().clamp_(0, 1)  # 1. ì •ê·œí™” í•´ì œ + ê°’ ë²”ìœ„ ì œí•œ (0~1)
    out_img_np = out_img.permute(1, 2, 0).cpu().numpy()                # 2. CPUë¡œ ì´ë™ í›„ numpy ë³€í™˜ (HWC í˜•íƒœ)
    out_img_np = (out_img_np * 255).round().astype('uint8')            # 3. 0~255 ë²”ìœ„ë¡œ ë³€í™˜ (ì†Œìˆ˜ì  ì²˜ë¦¬ ê°œì„ )
    out_img_pil = Image.fromarray(out_img_np)
```
<br/>

### **:boom:ì›Œí„°ë§ˆí¬ íƒì§€ ê¸°ëŠ¥**
```python
@app.route('/watermark-detection', methods=['POST'])
def watermarkDetection():
    # 1. ì´ë¯¸ì§€ ìˆ˜ì‹  ë° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    image_file = request.files.get('image')
    message = request.form.get('message', '')
    if not image_file or not message:
        return jsonify({"error": "image, message ë‘˜ ë‹¤ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
    # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image = Image.open(image_file.stream).convert("RGB")
    img_pt = default_transform(image).unsqueeze(0).to(device)
    
    # 3. ì›Œí„°ë§ˆí¬ íƒì§€ (ëª¨ë¸ ì¶”ë¡ )
    with torch.no_grad():
        detect_outputs = wam.detect(img_pt)
        preds = detect_outputs['preds']      # shape: [B, 1+nbits, H, W]
        mask_preds = preds[:, 0:1, :, :]     # ì˜ˆì¸¡ëœ ë§ˆìŠ¤í¬
        bit_preds = preds[:, 1:, :, :]       # ì˜ˆì¸¡ëœ ë©”ì‹œì§€ ë¹„íŠ¸
        
    # 4. ì˜ˆì¸¡ëœ ë¹„íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ì¶”ì¶œ
    pred_message = msg_predict_inference(bit_preds, mask_preds)
    pred_message_float = pred_message.float()  # float32ë¡œ ë³€í™˜
    
    # 5. ì›ë³¸ ë©”ì‹œì§€ í…ì„œ ë³€í™˜
    wm_bits = ''.join(f"{ord(c):08b}" for c in message.ljust(4, '\x00'))[:32]
    wm_tensor = torch.tensor([int(b) for b in wm_bits], dtype=torch.float32).to(device)
    
    # 6. ë¹„íŠ¸ ì •í™•ë„ ê³„ì‚°
    bit_acc = (pred_message_float == wm_tensor.unsqueeze(0)).float().mean().item()
    bit_acc_pct = round(bit_acc * 100, 1)
```
